---
title: 'Analyse de données RNA-Seq: alignement et quantification avec la suite Tuxedo'
author: "Denis Puthier"
date: "11 janvier 2016"
output:
  html_document:
    css: ../../stylesheets/course.css
    fig_caption: yes
    highlight: zenburn
    theme: cerulean
    toc: yes
    toc_depth: 3
  pdf_document:
    fig_caption: yes
    toc: no
    toc_depth: 3
  word_document: default
---




<script type="">
    $(function() {
        $(".hideshow").click(function() {
                $(this).parent().find(".solution").toggle();
        });
            
    })
</script>

<style> 
.solution {
  display:none;
}

pre:not(.sourceCode) > code {
  background-color: #2C3539!important;
  color: white;
} 
pre.text {
  background-color: #2C3539 !important;
}

hr {
  color: grey !important;
}
</style>



### Introduction

The “Tuxedo Suite” has been developed for RNA-Seq data analysis. It is mainly composed of Bowtie, Tophat, Cufflinks, CuffDiff. It is intended to provide powerful solutions for read mapping, discovery of novel gene structures and differential expression analysis. In the practical session we will use this suite to analyse samples obtained from P5424 thymocyte cell line.

-------------------------------------------------------------------


### Galaxy servers


The Galaxy server motto is “Data intensive biology for everyone”. Galaxy is a web-based framework for data intensive biomedical research. Galaxy can be install easily on any computer but is also proposed through remote access by numerous research groups. It is intended to ease the development of complexe workflows to analyze various types of biological data. Although it has been historically oriented toward NGS data analysis (ChIP-Seq, RNA-Seq, Ribosome profiling,…), lots of public servers are also proposing set of tools dedicated to genomics, proteomics, image analysis, cancer stem cell analysis (…). The [public server web page](https://wiki.galaxyproject.org/PublicGalaxyServers) of the galaxy team list all the publicly available servers throughout the world (n=70 at the time of writing).

-------------------------------------------------------------------

### Connecting to the pedagogix Galaxy server

**NB:** Note that the pedagogix server is only maintained for pedagogic purposes to propose privileged access to students from M2 BBSG and Polytech. It is not intended to be a production server as it is not heavily maintained.

- Open a connection to [pedagogix Galaxy server](http://pedagogix-tagc.univ-mrs.fr/galaxy/). If this is your first connection, use the Register command. Otherwise, enter your login (use Login in the User menu at the top of the Galaxy window).


-------------------------------------------------------------------

### Loading fastq files in galaxy

Analysis of the whole dataset would be time consuming. To make the analysis feasible within a reasonnable time, data were previously mapped to the mouse genome (version mm9). A subset of reads that aligned onto chromosome 18 was extracted and will be used for this tutorial. The following dataset are available.

File name | Experiment  | Description |
----------|-------------|-------------|
DM1_chr18_R1.fq.gz | control DMSO, replicate 1 | Right end read.
DM1_chr18_R2.fq.gz | control DMSO, replicate 1 | Left end read..
DM2_chr18_R1.fq.gz | control DMSO, replicate 2 | Right end read.
DM2_chr18_R2.fq.gz | control DMSO, replicate 2 | Left end read.
DM3_chr18_R1.fq.gz | control DMSO, replicate 3 | Right end read.
DM3_chr18_R2.fq.gz | control DMSO, replicate 3 | Left end read.
PI1_chr18_R1.fq.gz | PMA/Ionomycine treated, replicate 1 | Right end read.
PI1_chr18_R2.fq.gz | PMA/Ionomycine treated, replicate 1 | Left end read..
PI2_chr18_R1.fq.gz | PMA/Ionomycine treated, replicate 2 | Right end read.
PI2_chr18_R2.fq.gz | PMA/Ionomycine treated, replicate 2 | Left end read.
PI3_chr18_R1.fq.gz | PMA/Ionomycine treated, replicate 3 | Right end read.
PI3_chr18_R2.fq.gz | PMA/Ionomycine treated, replicate 3 | Left end read.

These datasets are available directly in Galaxy to avoid network issues. We will start by analysing the DM1 sample (control DMSO, replicate 1).

<div class="protocol">

- In the upper left corner, click on **Unnamed history** and rename this workspace to **DM1**.
- Select **Shared Data > Data Libraries > TlemCen 2016 > DM1 > DM1_chr18_R1.fq > Import this dataset into selected history**. In the new window select **DM1** as **Destination history**. Click on **Import library dataset**.
- Select **Analyse Data** in the upper menu.
- Select **Shared Data > Data Libraries > TlemCen 2016 > DM1 > DM1_chr18_R2.fq > Import this dataset into selected history**. In the new window select **DM1** as **Destination history**. Click on **Import library dataset**.
- Select **Analyse Data** in the upper menu.
- Click the eye icon to display the content of DM1_chr18_R1.fq file.
</div>

<div class="exo">
- How is the quality encoded ?
- What can you say about the quality of the first encountered reads ?
</div>

-------------------------------------------------------------------

### Quality control with FastQC

FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis. FastQC can be run as a stand alone interactive application (for the immediate analysis of small numbers of FastQ files) or in a non-interactive mode (through shell commands) where it would be suitable for processing large numbers of files.

It is important to stress that although the analysis results appear to give a pass/fail result, these evaluations must be taken in the context of what you expect from your library. A 'normal' sample as far as FastQC is concerned is random and diverse. Some experiments may be expected to produce libraries which are biased in particular ways. You should treat the summary evaluations therefore as pointers to where you should concentrate your attention and understand why your library may not look random and diverse.

This [web site](https://sequencing.qcfail.com/) provides you with some nice example of sequencing failures and may help you in analyzing fastqc outputs.


<div class="protocol">

- Use **NGS: QC and manipulation > FastQC:Read QC**.
- Select the first fastq file (**DM1_chr18_R1**) and press **Execute**.
- Display the data for the corresponding fastqc result (use the view (eyes) icon above the dataset name in the right panel).
- Carefully inspect all the statistics. 
</div>

Perform the same operation for **DM1_chr18_R2** file.

<div class="exo">
 - What do you think of the overall quality of the sequencing ?
 - Carefully inspect all diagrams. The [FastQC documentation](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules) contains a section that explains the meaning of each diagram/
 - What is the format of quality encoding. You need to know it to perform next step (read trimming).
</div>


------------------------------------------------------------------------

### Read trimming

Read trimming is a pre-processing step in which input read ends are cutted (most generally the right end). One should keep in mind that this step may be crucial depending on the aligner used. Indeed most aligners will be unable to align a large fraction of the dataset when poor quality ends are kept. Several software may be used to perform sequence trimming:


-   [FASTX-Toolkit](http://hannonlab.cshl.edu/fastx_toolkit/)
-   [sickle](https://github.com/najoshi/sickle)
-   [the ShortRead Bioconductor package](http://bioconductor.org/packages/2.11/bioc/html/ShortRead.html)
- ...

Here we will use sickle. 

<div class="protocol">

- Search for the sickle tool using the galaxy search engine (upper left corner). 
- Select sickle tool.
- Set **Single-End or Paired-End reads** to **Paired-end**.
- From **Paired-End Forward Strand FastQ Reads** dropdown list select 'DM1_chr18_R1'.
- From **Paired-End reverse Strand FastQ Reads** dropdown list select 'DM1_chr18_R2'.
- Set **Quality Threshold to 20, Length Threshold to 25** and press execute.
- Rename **Paired-End forward strand output of Sickle** to DM1_chr18_R1_trim
- Rename **Paired-End reverse strand output of Sickle** to DM1_chr18_R2_trim.
- Perform a new fastqc analysis using the trimmed read as input. 
- The number of reads should be reduced.

</div>

<div class="exo">
 - What does the **Singletons from Paired-End** file contain ?
 - Delete **Singletons from Paired-End** dataset.
 - How many read to you retrieve after trimming ?
 - How does it compare with the input fastq files ?
</div>

------------------------------------------------------------------------

### Getting the sequence of mouse chromosome 18 at UCSC

Most of the time the galaxy server will provide you with an already indexed genome that can be used by tophat to perform read alignment. In this practical, we would like to restrict the alignment to mouse chromosome 18 (this will be faster). We thus need to download the sequence of mouse chromosome 18. This sequence will be provided to tophat in the subsequent steps (tophat will perform sequence indexing internally by calling bowtie-build).

The sequence of the chr18 (mm9 build) can be downloaded through the [UCSC web site](http://hgdownload.soe.ucsc.edu/goldenPath/mm9/chromosomes/).

<div class="protocol">

- Go to the UCSC ftp web site. Copy the link adress to **chr18.fa.gz**.
- Select **Tools > Get Data > Upload File**. In the text area (**URL/Text**) paste the link to the chr18 sequence.
- Select **fasta** as **File Format** and **mm9** as a reference genome. Press Execute to import the sequence into your history.
- Rename the record in the history to **chr18_mm9.fa**.

</div>

<div class="exo">
- Check the first lines and last line of the file using head and tail respectively (**Text Manipulation > head-or-tail**).
- How to you explained the N stretch inside the sequence ?
</div>

**NB**: the chromosome sequence can also be obtained from [ensembl ftp web site](http://www.ensembl.org/info/data/ftp/index.html).

-------------------------------------------------------------------

### Getting the size of the chromosomes

Several programs need to know about chromosome length to perform dedicated task. Chromosome information can be obtained using **UCSC** whose **table-browser** is interfaced in Galaxy.


- Use **Get Data > UCSC Main table browser**.
- Set : **Clade** to Mammal, **Genome** to Mouse, **assembly** to "July 2007 (NCBI37/mm9)", **group** to **All tables**, **database** to mm9 and table to **chromInfo**. 
- Set **output format** to **all fields from selected table** and **Send output** to  **Galaxy**.
- In the new web page press **Send query to galaxy**.
- Rename the dataset to **mm9_chrom_info_txt**.


<div class="exo">
- What does this file content ?
- Use **Text Manipulation > Cut** and **Statistics > Summary Statistics** to compute the median size of a mouse chromosome.
</div>


-----------------------------------------------------------------

### Getting transcript annotation in gtf format

In order to provide topHat with the location of known exons in the human genome, we will download a file in GTF format (Gene transfer format). You can get more information about this format on [UCSC web site](https://genome.ucsc.edu/FAQ/FAQformat.html#format4) or [GENCODE](http://www.gencodegenes.org/gencodeformat.html) web site.

GTF file can be obtained both from **UCSC** [table browser](https://genome.ucsc.edu/cgi-bin/hgTables) or **ensembl** [ftp web site](http://www.ensembl.org/info/data/ftp/index.html). 

**NB**: it is very important at this step to ensure that the fasta file and the GTF file are obtained from the genome release (here mouse genome version mm9/GRCm37). The chromosome sequences and gene positions vary between genome releases.

**Here** we will use a GTF file containing information related to transcripts from mouse chromosome 18. This GTF file **was obtained from GENCODE** [web site](http://www.gencodegenes.org/mouse_stats/current.html) (Version M1 July 2011). Annotations are based on Ensembl server version 65. 

<div class="protocol">
- Select **Shared Data > Data Libraries > TlemCen 2016 > GTF >  chr18_20M-50M_gencode_vM1.gtf > Import this dataset into selected history**. In the new window select **DM1** as **Destination history**. Click on **Import library dataset**.
- Select **Analyse Data** in the upper menu.**.

</div>

<div class="exo">
- Check the first lines of the GTF file. What kind of information are enclosed in this file ?
</div>


-------------------------------------------------------------------

### Mapping read with TopHat

TopHat is a fast splice-aware junction mapper for RNA-Seq reads. It aligns RNA-Seq reads to mammalian-sized genomes using the ultra high-throughput short read aligner Bowtie, and then analyzes the mapping results to identify splice junctions between exons.

We will start by mapping the reads corresponding to control sample.

<div class="protocol">

- Select **NGS: Mapping > Tophat2** from the toolbox.
- Set "Is this library mate-paired?:" to "Paired-end".
- Set **RNA-Seq FASTQ file, forward reads** to "DM1_chr18_R1_trim".
- Set **RNA-Seq FASTQ file, reverse reads** to "DM1_chr18_R2_trim".
- Set **Use a built in reference genome or one from your history** to "Use a genome from history".
- Set **Select the reference genome** to **chr18_mm9.fa**.
- Set **TopHat settings to use** to **Full parameter list**.
- Set **Maximum number of alignments to be allowed** to 1.
- Set **Library Type** to **FR First strand**.
- Set **Use Own Junctions ** to **yes**.
- Set **Use Gene Annotation Model** to **yes**.
- Set **Gene Model Annotations** to ** chr18_20M-50M_gencode_vM1.gtf**.
- Press **Execute**.
- Rename the **accepted_hits** dataset to **DM1_alignments**. 
- Rename the 'splice-junction' bed file to DM1_splice_junctions.bed.
</div>


**NB:** By default tophat will accept reads whose genomic mapping is ambiguous. This multi-mapped reads may be problematic in the downstream analysis. Indeed, keeping them may introduce spurious transcript models when trying to reconstruct underlying transcripts. However discarding them may also be problematic when computing expression levels of gene families.
The **Maximum number of alignments to be allowed** argument instructs TopHat to allow up to this many alignments to the reference for a given read, and choose the alignments based on their alignment scores if there are more than this number. The default is 20 for read mapping. Depending on the need, more stringent policy may be choosen (e.g setting "Maximum number of alignments to be allowed" to 1 indicates that muti-mapped reads should be discarded). Additional arguments are available in the command line version of tophat including -x/--transcriptome-max-hits and -M/--prefilter-multihits.

<div class="exo">
- Is this GTF mandatory for tophat ?
- What is the benefit of providing tophat with a GTF ?
- What are the benefits and drawbacks when selecting 1 for argument **Maximum number of alignments to be allowed** ? What is your feeling  ?
</div>

-------------------------------------------------------------------


### Checking the number of aligned reads

We will used **samtools flagstat** to assess the number of aligned read available in the bam file.

- Select **Statistics > flagstat**.
- Select the **BAM** file and press **Execute**.

<div class="exo">
  - Check the statistics. Is that expected ?
  - How does it compare with the input right-end and left-end fastq files ?
</div>

<div class="exo">
- How does it compare with the number of trimmed reads ?
- How does it compare with the number of raw reads ?
</div>

------------------------------------------------------------------------


### Viewing the results with Integrated Genome Browser (IGV).

The Integrative Genomics Viewer (IGV) is a high-performance visualization tool for interactive exploration of large, integrated genomic datasets. It supports a wide variety of data types, including array-based and next-generation sequence data, and genomic annotations.

<div class="protocol">

- Create an IGV account [here](https://www.broadinstitute.org/igv/?q=registration).
- Download IGV and launch it with 750 MB or 1.2 Gb depending of your machine.
- Select **mm9** as a genome and browse to **chromosome 18**.
- In galaxy select tophat result (bam format) and download the **bam** file.
- In galaxy select tophat result (bam format) and download the **bai** file.
- In IGV, go to the **Egr1** gene (by typing 'Egr1' in the **GO** text area).
- Zoom to view alignments.
- In the left panel right click on the bam file name and select **View as pairs**.
- In the left panel right click on the bam file name and set **Color Alignments by > Read strand**.
- In galaxy select tophat result (**control_splice_junctions.bed**) and download the **bed** file. If this file does not contain a **bed** extension, rename it to add **.bed**.
- Load the **control_splice_junctions.bed** into IGV (File > Load from file).
- Unzoom to view the number of alignments supporting exon junctions.
- Mouse over a junction on of **control_splice_junctions.bed** track. What is the **Depth** about ?

</div>

<div class="exo">
- What is the strand of gene 'Egr1' ?
- What does the blue and pink color indicate ?
- Mouse over a paired read. What are the meanings of the following tags/keys:
    - CIGAR ?
    - Mapped ?
    - Mapping quality ?
    - Secondary ?
    - Duplicate ?
    - Mate-is mapped ?
    - Insert-size ?
    - Pair-orientation ?
    - First in pair ?
    - Second in pair ?
- What are the meaning of :
  - NH ?
  - NM ?
- Mouse over **several paired alignements** on Egr1. What are the value of the **pair-orientation** keys ?
- Go to internal exons of Etf1 (this gene is located just 40kb away on the 3' side of Egr1).
    - What is the strand of Etf1 ?
    - What are the values of  **pair-orientation** key on **paired alignements** ?
    - Look at additional gene examples.
    - What can you conclude regarding **paired alignements** values ?
    - How would you isolate the signal emitted from the plus and minus strands ?
- Looking at **Nr3c1** you will find some signal extensing from the 5' region ?
    - Is it produced by the plus or minus strand ?
</div>

-------------------------------------------------------------------

### Creating a bigwig track

As you may have notice the user needs to zoom inside IGV to visualize the alignments. This is due to the fact that BAM files may be very large (tens of Gb or more). Loading all information from the file would thus saturate the computer memory. We will thus create a more lightweight file that will just provide us with the mean coverage of each genomic region. This file in bigWig format will be compressed and indexed as the BAM files.

<div class="protocol">

- Use the **NGS: RNA Analysis > BAM to Wiggle ** tool to convert the BAM file to a wiggle format (the uncompressed and unindexed version of the BgigWig format).
- Set **Strand-specific** to **Paired-end**.
- Set **Pair-End Read Type** to **read1 (positive --> negative; negative --> positive), read2 (positive --> positive; negative --> negative)**.
- Set **Chromosome size file** to **mm9_chrom_info_txt**.
- Press **Execute**.

</div>

<div class="exo">
- Why does the output contain two files ?
</div>

<div class="protocol">
For the two wiggle files:

- Select **Convert Formats > Wig/BedGraph-to-bigWig**.
- Click on **Execute**.
- Rename the output obtained from ** Wiggle on Forward Reads** to **DM1_chr18_20M-50M_plus.bigwig**.
- Rename the output obtained from ** Wiggle on Reverse Reads** to **DM1_chr18_20M-50M_minus.bigwig**.
- Download the subsequent bigwig file and load it into **IGV**.
- In **IGV**, on the **left panel**, right click on the bigwig track name. Use **Set data range** and set the value **min, mid and max** value to **-200, 0, 200** respectively.
- Unzoom.
</div>

-------------------------------------------------------------------


### Searching for novel transcript with cufflinks

We can now use the cufflinks software to try to discover new transcripts inside the dataset. We will also provide cufflinks with the set of known transcript.

<div class="protocol">

- In the toolbox, select **NGS: RNA Analysis > Cufflinks**.
- Select the bam file in the **SAM or BAM file of aligned RNA-Seq reads** menu.
- Set **Set advanced Cufflinks options** to **yes**.
- Set **Use Reference Annotation** to **Use reference annotation as guide**.
- Set **Reference Annotation** to **chr18_20M-50M_gencode_vM1.gtf**.
- Set **Library prep used for input read** to **fr-firststranded**.
- Press **execute**.
- Rename **assembled transcript** dataset to **DM1_transcripts**.

</div>

<div class="exo">
- Have a look at the **assembled transcripts** file produced by cufflinks. What are the gene_ids, transcript_ids ?
- What additional information is provided ?
- Load the **assembled transcript** file produced by cufflinks into IGV.
  - What can we say about the transcripts produced by the **Pura** gene  ?
</div>

------------------------------------------------------------------------

### Extracting a workflow

Galaxy allows user to apply the developed pipeline to another set of sample. In order to do that, the user must create a **workflow**.

<div class="protocol">

- In the history menu, select **history options**.
- Click on **Extract workflow**.
- Set the name of the new workflow to **RNA-Seq mapping and transcript discovery.**.
</div>

<div class="exo">
- Using the menu go to  **workflow > RNA-Seq mapping and transcript discovery > edit**.
- Have a look at the worflow.
- Rename the input elements to **Read_1, Read_2,  CHROM_SIZE and GTF** according to their connections in the workflow.
</div>
------------------------------------------------------------------------

### Apply the workflow to PI1_chr18_20M-50M

We will now apply this workflow to the sample corresponding to **the activated thymocyte (replicate 1)**.

<div class="protocol">

- Create a new history: **History > Create new**.
- Rename this workspace : **PI1**.
- Select **Shared Data > Data Libraries > TlemCen 2016 **.
- Open all folder and select (radio button): **mm9_chr_size.txt**, **chr18_mm9_fa**, **chr18_20M-50M_gencode_vM1.gtf**, and the two fastq files from **PI1** sample. 
- Use **For selected datasets > import to current history** and click **GO**.
- Click on **Galaxy** (top left) to go back to your history (PM1). You should see the five datasets.
- In the top menu select **workflow > RNA-Seq mapping and transcript discovery > edit**. Have a look at your new workflow. Check the input files.  
- Select **workflow > RNA-Seq mapping and transcript discovery > run**. Set the proper input files.
- Click **Run workflow** at the bottom of the page.
- Rename **assembled transcript** dataset to **PI1_transcripts**.
- Rename the **accepted_hits** dataset to **PI1_alignments**. 
- Rename the 'splice-junction' bed file to **PI1_splice_junctions.bed**.
- Load the **PI1_splice_junctions.bed** and **PI1_alignments** files into IGV.
</div>


<div class="exo">

- Go to the **Egr1** gene. What can you see ?

</div>

------------------------------------------------------------------------

### Apply the worflow to all other samples (faculative)

You may apply the workflow to all replicates. Do to that, create successively an history for storing DM2, DM3, PI2 and PI3. Import the corresponding files into the history and run the workflow. Don't forget to import **mm9_chr_size.txt**, **chr18_mm9_fa** and **chr18_20M-50M_gencode_vM1.gtf** files.

------------------------------------------------------------------------


## Creating a workspace to compare samples from both classes

Create a new history entitled **DM versus PI**. Copy the datasets below in this history (use **history > Copy datasets**).

- The bam and bai files (accepted_hits that should have been renamed **PI1_alignments** and **DM1_alignments**) for all samples.
- The **assembled transcripts** files (cufflinks results) from all samples.
- The gtf file (**chr18_20M-50M_gencode_vM1.gtf**).
- The **mm9_chr_size.txt** file.

------------------------------------------------------------------------


## Merging the reference and infered genomic annotations

We now have at least three different GTF files (depending on whether you have processed DM2,DM3,PI2,PI3):

- The reference annotation
- The discovered transcripts in the control sample(s).
- The discovered transcripts in the activated sample(s).

We will ask **cuffmerge** to merge the novel annotations (obtained through cufflinks) with the reference (known annotation)  and to classify the transcripts. It will annotate transcripts by producing a GTF file containing flags. Some of this flags may indicate that:

- The transcript is unknown (class code "u").
- The transcript is a novel isoform of a known transcript (class code "j").
- The transcript is the same as the original/known transcript ((class code "=").
- ...

For a full description of all possible flags ("class code"), please refer to the [cuffmerge](http://cole-trapnell-lab.github.io/cufflinks/cuffcompare/) web site (section 'Transfrag class codes').

Here we will concentrate on retrieving the position of novel transcripts.

<div class="protocol">

- Now select **NGS: RNA Analysis > cuffmerge**. Set **GTF file(s) produced by Cufflink** to the two **assembled transcript** files (**DM1_transcripts**...). 
- Select **Use Reference Annotation**. Set **Reference Annotation** to **chr18_20M-50M_gencode_vM1.gtf**.
- Press **Execute**.
- Use **Filter and sort > Select lines that match an expression**. Select line containing **class_code "u"**. The 'u' indicate they are unknown genes (not present in the reference annotation).
- Merge this unknown transcript with the reference annotation (**chr18_20M-50M_gencode_vM1.gtf**) using **Text Manipulation > Concatenate datasets**. 
- Rename the file to **assembly.gtf**.
</div>


<div class="exo">
- How many transcripts were classified as unknown ?
</div>

----------------------------------------------------

## Quantification

The objective of quantification is to estimate the expression level of each gene by counting the number of reads overlapping each gene model. Several software have been developed for this task (cuffdiff, featureCount, HTSeq-count,...). The FeatureCounts software is a light-weight read counting program written entirely in the C programming language.  It has a variety of advanced parameters but its major strength is its outstanding performance (10GB SE BAM file takes about 7 minutes on a single average CPU).

<div class="protocol">

- Copy the two bam files in the **assemby and quantification** history.
- Select **NGS: RNA Analysis > featureCounts**.
- Select the two bam files in **Alignment file**.
- Set **GFF/GTF Source** to Use reference from history.
- Select **assembly.gtf** as Gene annotation file.
- Set **featureCounts parameters** to **extended settings**.
- Set **GFF feature type filter** to exon (we want to count inside exonic regions).
- Set **GFF gene identifier** to **gene_id** (all exons of all transcripts of a given gene will be summed up to get the final expression value).
- Set **Strand specific protocol** to **Stranded (reverse)"**.
- Set **Minimum read quality** to 12.
- Select **PE Count fragments instead of reads:**.
- Click **Execute**.
- Check the **Summary file**. What are **Unassigned_MultiMapping**, **Unassigned_NoFeatures**, **Unassigned_MappingQuality**, **Unassigned_Chimera** ?
</div>

----------------------------------------------------

## Differential expression analysis with DESeq2


----------------------------------------------------

## Descritive statistics with R

<div class="protocol">

- Download the gene expression table produced by featureCount.
- Rename the file to **raw_counts.txt**.
- Open **RStudio**.

```{r}
## First we read gene counts
count <- read.table("raw_counts.txt" ,sep="\t", head=T,row=1)
#head(count)
#head(rownames(count))
#colnames(count)

# Change column names
colnames(count) <- c("Activated", "Resting")
## Values are log2 transformed 
## (a pseudo-count is added in case one of the sample is equal or close to zero)
count <- log2(count +1)

## Checking distribution of FPKM values
hist(as.matrix(count), main="Distribution of count values")
boxplot(count, col=c("red","gray"), pch=16, main="Boxplot for count valaues")


## Scatter plot comparing expression levels in sample 1 and 2
par(xaxs='i',yaxs='i')
plot(count, pch=20, panel.first=grid(col="darkgray"))
identify(count[,1], count[,2],lab=rownames(count))

```
</div>


## What's about ENSG00000134460 ?

The gene ENSG00000134460 seems to be strongly induced during T-cell activation. Go to Ensembl genome Browser and use the search area to get some information about it. Is this positive regulation expected ?



-------------------------------------------------------------------

### The SRP000698 dataset

In the article entitled "**Genome-wide analysis of allelic expression imbalance in human primary cells by high-throughput transcriptome resequencing**" the authors have used RNA-Seq technology to compare the transcriptome of **actived and resting T-cells**. Using this technology they were also able to monitor allele-specific expression (ASE), that is, specific expression arising from maternally and paternally derived alleles. In this tutorial we will concentrate on mapping read to the genome and compute gene expression levels with the Tuxedo suite.


-------------------------------------------------------------------

### The Sequence Read Archive database


Gene Expression Omnibus ([GEO](http://www.ncbi.nlm.nih.gov/geo/)) and Sequence Read Archive ([SRA](http://trace.ncbi.nlm.nih.gov/Traces/sra/)) are public databases that provide tools to submit, access and mine functional genomics data. Data may be related to array- or sequence-based technologies. For HTS data, GEO provides both processed data (such as *.bed and *.wig files) and links to raw data. Raw data are available from the Sequence Read Archive (SRA) database (including 454, IonTorrent, Illumina, SOLiD, Helicos and Complete Genomics). Both web sites propose search engines to query their databases.

Here we will access the raw dataset through the SRA database

- The SRA Sequence Read Archive (SRA) web site can be accessed [here](http://trace.ncbi.nlm.nih.gov/Traces/sra/).
- The SRA Run browser (*Tools* section) can be used to search for a SRA object *Search &gt;SRA Objects*

<div class="exo">

1.  Get informations about the SRA study "SRP000698"
2.  What is the study about ?
3.  What platform was used ?
4.  How many reads were produced ?
5.  How many samples were analyzed ?
6.  Get informations about experiments "SRX011549" and "SRX011550"
    (SRA Objects)
7.  Which of these two samples is untreated or treated ?
9. What is the species used in this study ?
8.  How many runs were performed per samples ?
9.  Is this experiment single-end or paire-end sequencing ? What are the
    sizes of the reads ?
10. How many reads are available per run on average ? Calculate
    it roughly.
11. Select one run. What is the sequence of the first read ?
12. what is the quality of this read ?

</div>


-------------------------------------------------------------------


### Using ensembl genome browser to get information about BAG3 and ENST00000454541


Go to the ensembl [genome browser](http://www.ensembl.org/).

Get some information about BAG3:

<div class="exo">

- In the **search panel** select **Human**. In the text area of the search panel type **BAG3**.
- Click on entry **ENSG00000151929**. What is the meaning of the **ENSG** prefix ?
- What is the **description** associated to BAG3 ? What does **athanogene** mean ?
- Ask for **Show transcript table**. How many transcript are associated with BAG3 ?
- Does it correspond to the number of transcripts displayed in IGV. Do they have the same IDs ? What about the **ENST** prefix ?
- What is the **biotype of this transcript** ?
- Some links are provided toward **RefSeq** and **UniprotDB**. What kind of information do they store ?
- What are the known **phenotypes** associated with defect in this gene ?
- How many **orthologues** and **paralogues** are linked to human BAG3 ?

</div>

Get some information about : ENST00000454541

<div class="exo">

- What is the **gene identifier** of ENST00000454541 ?
- What is the length of its cDNA ?
- What is its associated **biotype** ?
- Go to [this web page](http://vega.sanger.ac.uk/info/about/gene_and_transcript_types.html) to get the definition associated with **Gene type**. What is a **Processed pseudogene** ?

</div>

------------------------------------------------------------------------

- GO to gene 'TODO'.
- In the TODO gene some exonic region are larger than others ? What are they ? Where are the 3' and 5' UTR regions ? <--- TODO
- In the left panel, right click on the GTF file name and click on **expand** to visualize all known isoforms of TODO <--- TODO
- What about the gene that is 6kb upstream (5' orientation) of BAG3. Does it appear in the IGV RefSeq track. What could it be ?
- To check if this transcript is included in ensembl annotation, retrieve the GTF file from Galaxy. Check if the file extension is correct (.gtf). Load it into Galaxy. 
- Is the transcript downstream to BAG3 part of ensembl annotation ?
- What about this trancript model ? Does it seem to multiexonic ? What would be roughly the cDNA length ? What kind of RNA could it be ?

